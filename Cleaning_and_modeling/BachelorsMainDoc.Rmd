---
title: "Bachelors Main Document"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

knitr::knit_engines$set(python = reticulate::eng_python)
```


```{r, Packages}

library(pacman)
p_load(
  reshape2,
  jsonlite,
  tidyverse,
  tm,
  topicmodels,
  parallel,
  tidytext,
  plotly,
  widyr,
  data.table,
  Morpho,
  pracma,
  plotly,
  lubridate,
  tidyr,
  LDAvis,
  servr,
  igraph,
  ggraph,
  text2vec,
  textmineR
)

```

```{r}
df <- readRDS("/home/ptrt/BachelorsProjectCOVID19NLP/full_tokenized_data.rds")

stop_ord <- read_csv("/home/ptrt/BachelorsProjectCOVID19NLP/custom_stop_words.csv")

table_df<- df %>%
    filter(upos %in% c("VERB", "NOUN", "ADV", "PROPN", "ADJ")) %>%
    anti_join(stop_ord) %>%
    count(lemma, CoronaStatus) %>%
    drop_na()
```

```{r, tfidf}

textLemmas <- df %>%
  drop_na() %>%
    filter(ner == "O") %>% 
  count(CoronaStatus,lemma, sort = T)

totalLemmas <- textLemmas %>% 
  drop_na() %>% 
  group_by(CoronaStatus) %>% 
  summarise(total = sum(n))

tfidf_df <- left_join(textLemmas,totalLemmas)

tfidf_df <- tfidf_df %>% 
  bind_tf_idf(lemma, CoronaStatus, n)

```


```{r, tfidf plot}
tfidf_df %>%
  group_by(CoronaStatus) %>%
  top_n(20, tf_idf) %>%
  ungroup() %>%
  mutate(CoronaStatus = as.factor(CoronaStatus),
         lemma = reorder_within(lemma, tf_idf, CoronaStatus)) %>%
  ggplot(aes(lemma, tf_idf, fill = CoronaStatus)) +
  geom_col(show.legend = FALSE) +
  labs(x = NULL, y = "tf-idf") +
  facet_wrap( ~ CoronaStatus, scales = "free_y") +
  coord_flip() +
  ggtitle("TF-IDF: NER-filtered") +
  scale_x_reordered() +
  scale_y_continuous(n.breaks = 3)
```

```{r, fig.height=5, fig.width=12}
textLemmasNames <- df %>%
  drop_na() %>% 
  filter(ner == "B-PER" | ner == "I-PER") %>% 
  count(CoronaStatus,lemma, sort = T) %>% 
  filter(n >= 25)

totalLemmasNames <- textLemmasNames %>% 
  drop_na() %>% 
  group_by(CoronaStatus) %>% 
  summarise(total = sum(n)) 

tfidf_dfNames <- left_join(textLemmasNames,totalLemmasNames)

tfidf_dfNames <- tfidf_dfNames %>% 
  bind_tf_idf(lemma, CoronaStatus, n)


tfidf_df <- tfidf_df %>%
  group_by(CoronaStatus) %>%
  top_n(20, tf_idf) %>%
  ungroup() %>%
  mutate(
    CoronaStatus = as.factor(CoronaStatus),
    lemma = reorder_within(lemma, tf_idf, CoronaStatus)
  )

tfidf_df %>%
  ggplot(aes(lemma, tf_idf, fill = CoronaStatus)) +
  geom_col(show.legend = FALSE) +
  labs(x = NULL, y = "Term Frequency–Inverse Document Frequency") +
  facet_wrap( ~ CoronaStatus, scales = "free_y") +
  coord_flip() +
  ggtitle("TF-IDF: Nouns, verbs adjectives, and adverbs only") +
  scale_x_reordered() +
  scale_y_continuous(n.breaks = 3)

ggsave("tfidfNoNames.png", width = 8, height = 5)

tfidf_dfNames <- tfidf_dfNames %>%
  group_by(CoronaStatus) %>%
  top_n(20, tf_idf) %>%
  ungroup() %>%
  mutate(
    CoronaStatus = as.factor(CoronaStatus),
    lemma = reorder_within(lemma, tf_idf, CoronaStatus)
  )


tfidf_dfNames %>%
  ggplot(aes(lemma, tf_idf, fill = CoronaStatus)) +
  geom_col(show.legend = FALSE) +
  labs(x = NULL, y = "Term Frequency–Inverse Document Frequency") +
  facet_wrap( ~ CoronaStatus, scales = "free_y") +
  coord_flip() +
  ggtitle("TF-IDF: Names Only") +
  scale_y_continuous(n.breaks = 3) +
  scale_x_reordered()

ggsave("tfidfNames.png", width = 8, height = 5)
```


```{r}
FuncLDA <- function(dataframe,stop_words,filter , k, seed = 1234){
dtm <- dataframe %>%
  filter(upos %in% c("VERB", "NOUN", "ADV", "PROPN", "ADJ")) %>%
  # filter(paper != "bt-print.ndjson" & paper != "ekstrabladet-print.ndjson" & paper != "kristeligt-dagblad-print.ndjson") %>% 
  anti_join(stop_ord) %>%
  # Count the number of occurrences
  count(ID, lemma) %>%
  group_by(lemma) %>%
  # Filter for corpus wide frequency
  filter(sum(n) >= filter) %>%
  # Ungroup the data
  ungroup() %>%
  # Create a document term matrix
  cast_dtm(document = ID,
           term = lemma,
           value = n)

lda <- LDA(dtm, k = k, control = list(seed = seed))
return(lda)
}

tidyLDA <- function(lda, filename){
tidy_lda <- tidy(lda)
tidy_lda %>% write_csv(filename)
return(tidy_lda)
}

PlotLDA <- function(tidyLDA, n, title){
  tidyLDA %>%
  group_by(topic) %>%
  top_n(n, beta) %>%
  ungroup() %>%
  arrange(topic, -beta)%>%
  mutate(term = reorder_within(term, beta, topic)) %>%
  group_by(topic, term) %>%    
  arrange(desc(beta)) %>%  
  ungroup() %>%
  ggplot(aes(term, beta, fill = as.factor(topic))) +
  geom_col(show.legend = FALSE) +
  coord_flip() +
  scale_x_reordered() +
  labs(title = title,
       x = NULL, y = expression(beta)) +
  facet_wrap(~ topic, ncol = 5, scales = "free")
}

topicmodels2LDAvis <- function(x, ...){
  post <- topicmodels::posterior(x)
  if (ncol(post[["topics"]]) < 3) stop("The model must contain > 2 topics")
  mat <- x@wordassignments
  LDAvis::createJSON(
    phi = post[["terms"]], 
    theta = post[["topics"]],
    vocab = colnames(post[["terms"]]),
    doc.length = slam::row_sums(mat, na.rm = TRUE),
    term.frequency = slam::col_sums(mat, na.rm = TRUE)
  )
}


topicmodels2pyLDAvis <- function(x, ...){
  post <- topicmodels::posterior(x)
  if (ncol(post[["topics"]]) < 3) stop("The model must contain > 2 topics")
  mat <- x@wordassignments
    list = list(
    phi = post[["terms"]], 
    theta = post[["topics"]],
    vocab = colnames(post[["terms"]]),
    doc.length = slam::row_sums(mat, na.rm = TRUE),
    term.frequency = slam::col_sums(mat, na.rm = TRUE)
  )
    return(list)
}
```


```{r}
baselineLDA <- df %>%
  filter(CoronaStatus == "Baseline") %>%
  FuncLDA(stop_ord, 50 , 8, seed = 1234)

baselineTidyLDA <- baselineLDA %>% tidyLDA("baselineLDA.csv")

# baselineTidyLDA %>%
#   PlotLDA(20, "Top 20 terms in each topic: Pre-Outbreak")
#serVis(topicmodels2LDAvis(baselineLDA), out.dir = "/home/ptrt/BachelorsProjectCOVID19NLP/baselineLDA")

#write_json(topicmodels2pyLDAvis(baselineLDA),"LDAvisModels/baselineLDAvis.json")
baselineLDAvis <- topicmodels2pyLDAvis(baselineLDA)

outbreakLDA <- df %>%
  filter(CoronaStatus == "Outbreak") %>% 
  FuncLDA(stop_ord,50 , 8, seed = 1234)

outbreakTidyLDA <- outbreakLDA %>% tidyLDA("OutbreakLDA.csv")

# outbreakTidyLDA %>% PlotLDA(20,"Top 20 terms in each topic: Outbreak") %>% ggplotly()

#write_json(topicmodels2pyLDAvis(outbreakLDA),"LDAvisModels/outbreakLDAvis.json")
#serVis(topicmodels2LDAvis(outbreakLDA), out.dir = "/home/ptrt/BachelorsProjectCOVID19NLP/OutbreakLDA")
outbreakLDAvis <- topicmodels2pyLDAvis(outbreakLDA)

postOutbreakLDA <- df %>%
  filter(CoronaStatus == "PostOutbreak") %>% 
  FuncLDA(stop_ord,50 , 8, seed = 1234)

postOutbreakTidyLDA <- outbreakLDA %>% tidyLDA("PostOutbreakLDA.csv")

# postOutbreakTidyLDA %>%
#   PlotLDA(20,"Top 20 terms in each topic: Post-Outbreak")

#serVis(topicmodels2LDAvis(outbreakLDA), out.dir = "/home/ptrt/BachelorsProjectCOVID19NLP/PostOutbreakLDA")
#write_json(topicmodels2pyLDAvis(postOutbreakLDA),"LDAvisModels/postOutbreakLDAvis.json")
postOutbreakLDAvis <- topicmodels2pyLDAvis(postOutbreakLDA)
```


```{r}
py <- reticulate::py

pyLDAvis<- reticulate::import("pyLDAvis")

pybaselineLDAvis = pyLDAvis$prepare(
  topic_term_dists = baselineLDAvis$phi,
  doc_topic_dists = baselineLDAvis$theta,
  doc_lengths = baselineLDAvis$doc.length,
  vocab = baselineLDAvis$vocab,
  term_frequency = baselineLDAvis$term.frequency
)

pyLDAvis$save_html(pybaselineLDAvis, "LDAvisModels/baselineLDAvis.html")


pyOutbreakLDAvis = pyLDAvis$prepare(
  topic_term_dists = outbreakLDAvis$phi,
  doc_topic_dists = outbreakLDAvis$theta,
  doc_lengths = outbreakLDAvis$doc.length,
  vocab = outbreakLDAvis$vocab,
  term_frequency = outbreakLDAvis$term.frequency
)

pyLDAvis$save_html(pyOutbreakLDAvis, "LDAvisModels/outbreakLDAvis.html")

pyPostOutbreakLDAvis = pyLDAvis$prepare(
  topic_term_dists = postOutbreakLDAvis$phi,
  doc_topic_dists = postOutbreakLDAvis$theta,
  doc_lengths = postOutbreakLDAvis$doc.length,
  vocab = postOutbreakLDAvis$vocab,
  term_frequency = postOutbreakLDAvis$term.frequency
)

pyLDAvis$save_html(pyPostOutbreakLDAvis, "LDAvisModels/postOutbreakLDAvis.html")

```

```{r}

baselineLDAvis$phi %>%
  GetTopTerms(20) %>%
  as.tibble()

outbreakLDAvis$phi %>%
  GetTopTerms(20) %>%
  as.tibble()

postOutbreakLDAvis$phi %>%
  GetTopTerms(20) %>%
  as.tibble()

baselineLDAvis$phi %>%
  GetTopTerms(20)  %>%
  as.tibble() %>%
  write_csv("baselineLDATopTerms.csv")

outbreakLDAvis$phi %>%
  GetTopTerms(20) %>%
  as.tibble() %>%
  write_csv("outbreakLDATopTerms.csv")

postOutbreakLDAvis$phi %>%
  GetTopTerms(20) %>%
  as.tibble() %>%
  write_csv("postOutbreakLDATopTerms.csv")
```


```{r}
getVocab <- function(texts){
it = itoken(texts, progressbar = T, n_chunks = 10, preprocessor = tolower)
vocab = create_vocabulary(it)
vocab = prune_vocabulary(vocab, term_count_min = 5L)

return(vocab)}
```

```{r}

df2 <-
  df %>% filter(upos %in% c("VERB", "NOUN", "ADV", "PROPN", "ADJ")) %>%
  anti_join(stop_ord) %>%
  mutate(lemma = paste(lemma, upos, sep = "_")) %>%
  group_by(ID) %>%
  mutate(text = glue::glue_collapse(lemma, " ")) %>% 
  dplyr::select(c("ID", "date", "paper", "CoronaStatus", "text")) %>%
  unique()
```

```{r}
baselineVocab <- df2 %>% filter(date < ymd("2020-02-26") ) %>% .$text %>% getVocab()
outbreakVocab<- df2 %>% filter(date > ymd("2020-02-28") & date < ymd("2020-04-12")) %>% .$text %>% getVocab()
postOutbreakVocab <- df2 %>% filter( date > ymd("2020-04-12")) %>% .$text %>% getVocab()

totalVocab <- rbind(baselineVocab,outbreakVocab,postOutbreakVocab) %>% dplyr::select(term) %>% unique()
```

```{r}
gloveFunc <- function(texts){
it = itoken(texts, progressbar = T, n_chunks = 10, preprocessor = tolower)
vocab = create_vocabulary(it)
vocab = prune_vocabulary(vocab, term_count_min = 5L)

# Use our filtered vocabulary
vectorizer = vocab_vectorizer(vocab)
# use window of 5 for context words
tcm = create_tcm(it, vectorizer, skip_grams_window = 6L)

glove = GlobalVectors$new(rank = 150, x_max = 50)
wv_main = glove$fit_transform(tcm, n_iter = 30, convergence_tol = 0.05, n_threads = 16)

wv_context = glove$components
word_vectors = wv_main + t(wv_context)
return(word_vectors)}

baselineGloVe <- df2 %>% filter(date < ymd("2020-02-26") ) %>%
  .$text %>%
  gloveFunc()

outbreakGloVe <- df2 %>%
  filter(date > ymd("2020-02-28") & date < ymd("2020-04-12")) %>%
  .$text %>%
  gloveFunc()

postOutbreakGloVe <- df2 %>%
  filter( date > ymd("2020-04-12")) %>%
  .$text %>%
  gloveFunc()
```


```{r, fig.height=15, fig.width=20}
coSimFunc <- function(word_vectors,word,top_n, CoronaStatus){
 word_vector = word_vectors[word, , drop = FALSE]
  cos_sim = sim2(
    x = word_vectors,
    y = word_vector,
    method = "cosine",
    norm = "l2"
  ) %>% as.data.frame()
cos_sim["lemma"] <- rownames(cos_sim)
cos_sim["similarity"] <- cos_sim[word] 

cos_sim<- cos_sim %>%
  arrange(desc(similarity)) %>%
  head(top_n +1) %>% 
  filter(lemma != word) %>% 
  mutate(CoronaStatus = CoronaStatus)
return(cos_sim)
}
merge_searches <- function(word,top_n = 15 , baseline = baselineGloVe, outbreak = outbreakGloVe, postOutbreak =postOutbreakGloVe) {
  
  baseline = try(baseline %>% coSimFunc(word,top_n,"Baseline"), silent = T)
  outbreak = try(outbreak %>% coSimFunc(word,top_n,"Outbreak"), silent = T)
  postOutbreak = try(postOutbreak %>% coSimFunc(word,top_n,"PostOutbreak"), silent = T)

df = rbind(baseline,outbreak,postOutbreak) %>%
  filter(CoronaStatus == "Baseline" | CoronaStatus == "Outbreak" |CoronaStatus == "PostOutbreak")
return(df)
}

```

```{r, fig.height=6, fig.width=12}
factor_levels <-
    levels(as.factor(c("Baseline", "Outbreak", "PostOutbreak")))

search_and_plot <-
    function(word,
             top_n = 15 ,
             baseline = baselineGloVe,
             outbreak = outbreakGloVe,
             postOutbreak = postOutbreakGloVe) {
        baseline = try(baseline %>% coSimFunc(word, top_n, "Baseline"), silent = T)
        outbreak = try(outbreak %>% coSimFunc(word, top_n, "Outbreak"), silent = T)
        postOutbreak = try(postOutbreak %>% coSimFunc(word, top_n, "PostOutbreak"),
                           silent = T)
        
        df = rbind(baseline, outbreak, postOutbreak) %>%
            filter(
                CoronaStatus == "Baseline" |
                    CoronaStatus == "Outbreak" |
                    CoronaStatus == "PostOutbreak"
            )
        df %>%
            mutate(
                CoronaStatus = as.factor(CoronaStatus),
                lemma1 = reorder_within(as.factor(lemma), as.numeric(similarity), CoronaStatus)
            ) %>%
            ggplot(aes(lemma1, as.numeric(as.character(similarity)), fill = CoronaStatus)) +
            geom_col(show.legend = FALSE) +
            labs(x = NULL, y = "similarity") +
            coord_flip() +
            facet_wrap(~ CoronaStatus, scales = "free_y") +
            scale_x_reordered() +
            scale_y_continuous(n.breaks = 5) +
            ggtitle(paste("Top", top_n, "words related to:", word)) +
            scale_fill_discrete(drop = TRUE,
                                limits = factor_levels)
}

search_and_plot("danmark_propn")
ggsave("danmarkGloVe.png", height = 5, width = 8)

search_and_plot("test_noun")
ggsave("testGloVe.png", height = 5, width = 8)

search_and_plot("isolation_noun")
ggsave("isolationGloVe.png", height = 5, width = 8)

search_and_plot("sygdom_noun")
ggsave("sygdomGloVe.png", height = 5, width = 8)

search_and_plot("isolere_verb")
ggsave("isolereGloVe.png", height = 5, width = 8)

search_and_plot("økonomi_noun")
ggsave("økonomiGloVe.png", height = 5, width = 8)

search_and_plot("smitte_verb")
ggsave("smitteGloVe.png", height = 5, width = 8)

```



```{r}
save.image("modelingWorkspace.RData")

rm(cluster)
rm(py)
rm(pybaselineLDAvis)
rm(pyLDAvis)
rm(pyOutbreakLDAvis)
rm(test)
rm(df)
rm(df2)
rm(df1)
rm(full_df)
rm(
  cluster,
  import,
  outbreakLDA,
  outbreakVocab,
  outbreakTidyLDA,
  outbreakLDAvis,
  postOutbreakLDA,
  postOutbreakLDAvis,
  postOutbreakTidyLDA,
  postOutbreakVocab,
  baselineLDA,
  baselineLDAvis,
  baselineTidyLDA,
  baselineVocab,
  stop_ord,
  totalLemmas,
  totalLemmasNames, 
  textLemmas,
  textLemmasNames,
  pybaselineLDAvis,
  py,
  pyLDAvis,
  pyOutbreakLDAvis,
  pyPostOutbreakLDAvis,
  tcm,
  vocab,
  it
)
save.image("/home/ptrt/BachelorsProjectCOVID19NLP/HOPE_SemTrackR_Shiny/workspace.RData")

load("modelingWorkspace.RData")

sessioninfo::session_info()


```

